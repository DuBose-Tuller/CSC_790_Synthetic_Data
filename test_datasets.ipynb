{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d987df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from model_evaluation_pipeline import run_three_models_training, test_all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488ca1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'is_fit'\n",
    "N_RUNS = 1\n",
    "\n",
    "# Static test file location\n",
    "test_file = 'data/fitness/original/test.csv'\n",
    "\n",
    "# Find all train.csv files in subfolders of data/fitness/ (excluding 'original')\n",
    "data_dir = Path('data/fitness')\n",
    "train_files = [f for f in data_dir.rglob('**/*.csv') if 'original' not in f.parts]\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Iterate over each train file\n",
    "for train_file in train_files:\n",
    "    try:\n",
    "        # Run multiple times to get error bars\n",
    "        all_runs = []\n",
    "        for run_idx in range(N_RUNS):\n",
    "            # Train models\n",
    "            training_results = run_three_models_training(str(train_file), TARGET, random_state=None)\n",
    "            # Test all models\n",
    "            test_results = test_all_models(training_results, test_file, TARGET)\n",
    "            all_runs.append(test_results)\n",
    "        \n",
    "        results[str(train_file)] = all_runs\n",
    "        print(f\"Processed {train_file.parent.name} ({N_RUNS} runs)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {train_file}: {e}\")\n",
    "        results[str(train_file)] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978174c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Organize data by method and model type\n",
    "data_by_model = {\n",
    "    'logistic': {},\n",
    "    'random_forest': {},\n",
    "    'hist_gradient': {}\n",
    "}\n",
    "\n",
    "for filename, all_runs in results.items():\n",
    "    if not all_runs:\n",
    "        continue\n",
    "    \n",
    "    # Extract method and percentage using regex\n",
    "    # Pattern: data/fitness/{method}/minority_{percentage}pct...\n",
    "    match = re.search(r'data/fitness/([^/]+)/minority_(\\d+)pct', filename)\n",
    "    \n",
    "    if match:\n",
    "        method = match.group(1)\n",
    "        percentage = int(match.group(2))\n",
    "        \n",
    "        # For each model type, collect all runs\n",
    "        for model_name in ['logistic', 'random_forest', 'hist_gradient']:\n",
    "            if method not in data_by_model[model_name]:\n",
    "                data_by_model[model_name][method] = {'percentages': [], 'roc_means': [], 'roc_stds': []}\n",
    "            \n",
    "            # Collect ROC AUC scores from all runs\n",
    "            roc_scores = [run[model_name]['test_roc'] for run in all_runs]\n",
    "            \n",
    "            data_by_model[model_name][method]['percentages'].append(percentage)\n",
    "            data_by_model[model_name][method]['roc_means'].append(np.mean(roc_scores))\n",
    "            data_by_model[model_name][method]['roc_stds'].append(np.std(roc_scores))\n",
    "\n",
    "# Sort each method's data by percentage for each model\n",
    "for model_name in data_by_model:\n",
    "    for method in data_by_model[model_name]:\n",
    "        sorted_data = sorted(zip(\n",
    "            data_by_model[model_name][method]['percentages'],\n",
    "            data_by_model[model_name][method]['roc_means'],\n",
    "            data_by_model[model_name][method]['roc_stds']\n",
    "        ))\n",
    "        data_by_model[model_name][method]['percentages'], \\\n",
    "        data_by_model[model_name][method]['roc_means'], \\\n",
    "        data_by_model[model_name][method]['roc_stds'] = zip(*sorted_data)\n",
    "\n",
    "# Create three separate plots\n",
    "model_titles = {\n",
    "    'logistic': 'Logistic Regression',\n",
    "    'random_forest': 'Random Forest',\n",
    "    'hist_gradient': 'Histogram Gradient Boosting'\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, (model_name, ax) in enumerate(zip(['logistic', 'random_forest', 'hist_gradient'], axes)):\n",
    "    for method, data in data_by_model[model_name].items():\n",
    "        percentages = np.array(data['percentages'])\n",
    "        means = np.array(data['roc_means'])\n",
    "        stds = np.array(data['roc_stds'])\n",
    "        \n",
    "        ax.errorbar(percentages, means, yerr=stds, marker='o', capsize=5, label=method)\n",
    "    \n",
    "    ax.set_xlabel('Minority Percentage (%)')\n",
    "    ax.set_ylabel('ROC AUC')\n",
    "    ax.set_title(f'{model_titles[model_name]}')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaebec81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
